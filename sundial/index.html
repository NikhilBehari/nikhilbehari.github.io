<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SUNDIAL</title>

    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/codemirror.min.js"></script>
    <script src="js/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="col-md-12 text-center" id="title">
                <b>SUNDIAL</b>: 3D Satellite Understanding through Direct, Ambient, and Complex Lighting Decomposition
                <small>
                    CVPR EarthVision 2024
                </small>
            </h2>
        </div>
        <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="author-table">
                    <tr>
                        <td>
                            <a style="text-decoration:none" href="">
                              Nikhil Behari
                        </td>
                        <td>
                            <a style="text-decoration:none" href="https://akshatdave.github.io">
                              Akshat Dave
                        </td>
                        <td>
                            <a style="text-decoration:none" href="">
                             Kushagra Tiwary
                        </td>
                        <td>
                            <a style="text-decoration:none" href="">
                              William Yang
                        </td>
                        <td>
                            <a style="text-decoration:none" href="">
                              Ramesh Raskar
                        </td>
                    </tr>
                </table>
            </div>
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="uni-table">
                    <tr>
                        <td>
                            <a style="text-decoration:none" href="https://www.media.mit.edu/groups/camera-culture/overview/"> MIT Media Lab </a>
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </div>
    <!-- <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script> -->
    <div class="container" id="main">
        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/papers/Behari_SUNDIAL_3D_Satellite_Understanding_through_Direct_Ambient_and_Complex_Lighting_CVPRW_2024_paper.pdf">
                            <img src="./img/pdf.png" height="50px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                                <a href="https://ieee-dataport.org/open-access/data-fusion-contest-2019-dfc2019" target="_blank">
                                <img src="./img/data.png" height="50px"> 
                                <h4><strong>Data</strong></h4> 
                                </a>
                        </li> 
                    </ul>
                    
                </div>
        </div>

        <div class="row">
            <div class="col-md-10 col-md-offset-1 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <img src="./img/canopy-teaser.png" width="100%">
                    </li>
                </ul>
            </div>
        </div>

        <br/>
        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h4>
                    Abstract
                </h4>
                <p class="text-justify">
                    3D modeling from satellite imagery is essential in areas of environmental science, urban planning, agriculture, and disaster response. However, traditional 3D modeling techniques face unique challenges in the remote sensing context, including limited multi-view baselines over extensive regions, varying direct, ambient, and complex illumination conditions, and time-varying scene changes across captures. In this work, we introduce SUNDIAL, a comprehensive approach to 3D reconstruction of satellite imagery using neural radiance fields. We jointly learn satellite scene geometry, illumination components, and sun direction in this single-model approach, and propose a secondary shadow ray casting technique to 1) improve scene geometry using oblique sun angles to render shadows, 2) enable physically-based disentanglement of scene albedo and illumination, and 3) determine the components of illumination from direct, ambient (sky), and complex sources. To achieve this, we incorporate lighting cues and geometric priors from remote sensing literature in a neural rendering approach, modeling physical properties of satellite scenes such as shadows, scattered sky illumination, and complex illumination and shading of vegetation and water. We evaluate the performance of SUNDIAL against existing NeRF-based techniques for satellite scene modeling and demonstrate improved scene and lighting disentanglement, novel view and lighting rendering, and geometry and sun direction estimation on challenging scenes with small baselines, sparse inputs, and variable illumination.                </p>
            </div>
        </div>

        <br/><div class="row"><div class="col-md-10 col-md-offset-1"><h4>
            Casting
        </h4></div></div>
        <div class="row">
            <div class="col-md-10 col-md-offset-1 text-center">
                
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <img src="./img/canopy_casting.png" width="100%">
                    </li>
                </ul>
            </div>
        </div>

        
        <br/><div class="row"><div class="col-md-10 col-md-offset-1"><h4>
            Results
        </h4></div></div>
        <div class="row">
            <div class="col-md-10 col-md-offset-1 text-center">
                
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <img src="./img/canopy-comp.png" width="100%">
                    </li>
                </ul>
            </div>
        </div>





</body></html>
